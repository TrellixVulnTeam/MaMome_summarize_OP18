14_PARAGRAPHS

3.3.1. Regression
The use of linear models enables simple ﬁtting of continuous
traits y as a function of feature vectors. However, if m ≥ n then
structural overﬁtting occurs, and even if m < n accuracy is often
improved by using penalized (regularized) models. For the model
y = Xβ + ǫ, the training loss is Pi(yi − ˆyi)2 the most commonly-
used regularization methods are ridge regression (Hoerl and
Kennard, 1970) and Lasso (Tibshirani, 1996) regression, which
respectively use penalties λ Pi β2
i and λ Pi |βi| (not including
the intercept) to the training loss. For binary class prediction,
the approach is essentially the same, applying a generalized linear (logit) model, with the negative log-likelihood as the training loss.
Here λ is a tuning parameter that can be optimized as part of
cross-validation. Both methods provide “shrunken” coeﬃcients,
i.e., closer to zero than an ordinary least-squares approach. The
results for Lasso are also sparse, with no more than n non-zero
coeﬃcients after optimization, and thus Lasso is also a feature-
selection method. Another variant is the elastic net (Zou and
Hastie, 2005), an intermediate version that linearly combines
both penalties.

3.3.2. Linear Discriminant Analysis (LDA)
For binary traits, this approach ﬁnds a linear combination of
OTUs in the training data that models the multivariate mean
diﬀerences between classes (Lachenbruch and Goldstein, 1979).
Classical LDA assumes that feature data arise from two diﬀerent
multivariate normal densities according to y = 0 and y = 1,
i.e., MVN(µ0, 6) and MVN(µ1, 6) (Figure 1A). The prediction
value is the estimate of the posterior mean E(Y|x) = Pr(Y =
1|X), used because it minimizes mean-squared error.

3.3.6. Random Forests
Random forests (Breiman, 2001) are an increasingly used
method, extensively applied in many diﬀerent ﬁelds, including
computational biology and genomics (Statnikov et al., 2013) Frontiers in Genetics | www.frontiersin.org 4 June 2019 | Volume 10 | Article 579 Zhou and Gallins Host Trait Prediction FIGURE 1 | Schematic illustration of several machine learning prediction methods using case/control (red/blue) status. For two features, (A) illustrates linear
discrimination methods. The solid line shows the linear discriminant line corresponding to equally probable outcomes, while the dashed line shows the midpoint of the
maximum-margin support vector machine. (B) For k-nearest neighbors, the gray point is predicted using an average of the neighbors (red, in this instance). (C)
Decision tree ensembles include random forests, which average over bootstrapped trees, and boosted trees, where successive residuals are used for ﬁtting. Trees may
not extend to the level of individual observations, and modal or mean values in the terminal nodes are used for prediction. (D) A neural network with few hidden layers.

refer 3.3.8. Neural Networks
Neural networks
to an interconnected feed-forward
network of nodes (“neurons”) with weights attached to each
edge in the network, which allows the network to form a
mapping between the inputs X and the outcomes y (Ditzler
et al., 2015a). Each neuron j receiving an input pj(t) from
predecessor neurons consists of the following components: an
activation aj(t), a threshold θj, an activation function f
that
computes the new activation at a given time t + 1, and an output
function fout computing the output from the activation. These
networks contain either one or many hidden layers, depending
on the network type (Figure 1D). For microbiome data, the input
layer is the set of OTUs, with separate neurons for each OTU.
Hidden layers use backpropagation to optimize the weights of
the input variables in order to improve the predictive power of
the model. The total number of hidden layers and number of
neurons within each hidden layer are speciﬁed by the user. All
neurons from the input layer are connected to all neurons in
the ﬁrst hidden layer, with weights representing each connection.
This process continues until the last hidden layer is connected Frontiers in Genetics | www.frontiersin.org 5 June 2019 | Volume 10 | Article 579 Zhou and Gallins Host Trait Prediction TABLE 1 | Review of published prediction accuracy comparisons.

Paper Dataset Trait Samples Cases Controls Taxa Level Method Metric Value Pasolli et al., 2016 Qin et al., 2014 Liver cirrhosis 232 118 114 542 Species Random forest Zeller et al., 2014 Colorectal cancer 121 48 73 503 Species Random forest Qin et al., 2010 IBD 110 25 85 443 Species Random forest Le Chatelier et al.,
2013 Obesity 253 164 89 465 Species Random forest Qin et al., 2012 Type II diabetes 344 170 174 572 Species Random forest Karlsson et al.,
2013 Type II diabetes 96 53 43 381 Species Random forest SVM Elastic net Lasso SVM Elastic net Lasso SVM Elastic net Lasso SVM Elastic net Lasso SVM Elastic net Lasso SVM Elastic net Lasso Johnson et al.,
2016 Post-mortem
interval (PMI) 67 NA NA 52 Phylum Ridge Ditzler et al.,
2015b Soil pH
(low/medium/high) Rousk, 2010 22 NA NA 500 Various 52 Phylum Elastic net 3,130 Species Lasso 52 Phylum SVM 3,130 Species Ridge 3,130 Species Elastic net 52 Phylum Lasso AUC AUC AUC AUC AUC AUC AUC AUC AUC AUC AUC AUC AUC AUC AUC AUC AUC AUC AUC AUC AUC AUC AUC AUC Error rate Error rate Error rate Error rate Error rate Error rate Error rate Error rate 0.95 0.92 0.91 0.88 0.87 0.81 0.79 0.73 0.89 0.86 0.83 0.81 0.66 0.65 0.64 0.60 0.74 0.66 0.70 0.71 0.76 0.66 0.60 0.54 0.46 0.48 0.49 0.50 0.51 0.52 0.52 0.15 Caporaso et al.,
2011 Host gender 1,967 NA NA 500 various Error rate 0.15 Recursive neural network
(RNN)
(50) Deep belief network (DBN)
(500) Deep belief network (DBN)
(750) Random forest Multi-layer perceptron
Neural network (MLPNN)
(500) Recursive neural network
(RNN) (250) Recursive neural network
(RNN) (500) Deep belief network (DBN)
(250) Deep belief network (DBN)
(500) Error rate 0.08 Error rate 0.08 Error rate Error rate 0.15 0.00 Error rate 0.19 Error rate 0.24 Error rate 0.24 (Continued) Frontiers in Genetics | www.frontiersin.org 6 June 2019 | Volume 10 | Article 579 Zhou and Gallins TABLE 1 | Continued Paper Dataset Trait Samples Cases Controls Taxa Level Method Metric Value Caporaso et al.,
2011 Three body sites 1,967 NA NA 500 Various Error rate 0.17 Reiman et al.,
2017 Caporaso et al.,
2011 Three body sites 1,967 NA NA 1,706 Various Accuracy 0.83 Moitinho-Silva
et al., 2017 Microbial
abundance from
sponges (high/low) 1,232 NA NA 30 Phylum random forest Accuracy 0.97 76 Class Random forest 2,322 Various Random forest Ai et al., 2017 141 42 99 1,171 Species Bayes net Colorectal cancer
(CRC) 141 53 88 783 Species Bayes net Wu et al., 2018 Three diseases 806 423 383 300 Genus Logistic Frontiers in Genetics | www.frontiersin.org 7 June 2019 | Volume 10 | Article 579 Host Trait Prediction Error rate Error rate 0.03 0.08 Error rate 0.16 Error rate 0.03 Error rate 0.03 Error rate Error rate 0.01 0.01 Accuracy 0.84 Accuracy 0.97 Accuracy 0.97 Accuracy 0.99 Accuracy Accuracy 0.99 0.95 Accuracy 0.99 Accuracy 0.95 Accuracy Accuracy Accuracy Accuracy AUC AUC AUC AUC AUC AUC F1 F1 F1 F1 0.95 0.91 0.50 0.91 0.93 0.94 0.98 0.86 0.86 0.71 0.91 0.86 0.83 0.91 (Continued) Random forest Multi-layer perceptron
neural network (MLPNN)
(500) Recursive neural network
(RNN) (250) Recursive neural network
(RNN) (500) Deep belief network (DBN)
(250) Deep belief network (DBN)
(500) Random forest Multi-layer perceptron
neural network (MLPNN)
(500) Recursive neural network
(RNN) (250) Recursive neural network
(RNN) (500) Deep belief network (DBN)
(250) Deep belief network (DBN)
(500) Multi-layer perceptron
Neural network (MLPNN)
(500) Random forest Convolutional neural
Network (CNN-1D) Convolutional neural
Network (CNN-2D) Adaptive boosting
(AdaBoost) Adaptive boosting
(AdaBoost) Adaptive boosting
(AdaBoost) Random forest Logistic Random forest Logistic k-nearest neighbor Random forest SVM Zhou and Gallins TABLE 1 | Continued Host Trait Prediction Paper Dataset Trait Samples Cases Controls Taxa Level Method Metric Value Nakano et al.,
2018 Oral malodour 90 45 45 37 Genus Asgari et al., 2018 HMP Five body sites 1,192 NA NA 20,589 Various Random forest Gevers et al., 2014 Crohn’s disease 1,359 731 628 9,511 Various Random forest Gradient boosting Adaptive boosting SVM
Deep learning SVM SVM Accuracy
Accuracy F1 F1 F1 F1 F1 F1 0.87 0.90 0.79
0.97 0.89 0.85 0.74 0.68 FIGURE 2 | (A–C) ROC curves for each machine learning method using all OTUs. The AUC values are shown in the legend. The size of each dataset (#
cases/controls ×# OTUs) is shown in the title. (D) Bar graph showing the average Pearson correlation (R) between predicted and actual BMI in the Goodrich dataset,
using BMI as a continuous trait.

The prediction Pearson correlation (R) between cross-
is a commonly-
validated predicted and actual y values
used standard of accuracy for continuous traits, although
many procedures are designed to minimize the mean-squared
prediction error Pi(yi − ˆyi)2. R ≤ 0 corresponds to no predictive
value, and R = 1 to perfect prediction. We advocate R as a
criterion because it is simple and applicable to many prediction
procedures. Some prediction procedures may have an oﬀset or
proportional bias in prediction that may harm the mean-squared
error, even if R is favorable. A post-hoc linear rescaling of the Frontiers in Genetics | www.frontiersin.org 8 June 2019 | Volume 10 | Article 579 Zhou and Gallins Host Trait Prediction prediction to “ﬁx” any such bias is straightforward, and we ﬁnd it
simplest to directly use R for comparison.

4. DATA USED FOR COMPARISONS 4.1. A Literature Review
We conducted a literature review of published host-trait
microbiome prediction studies that used cross-validation and
reported a measure of prediction accuracy. We conducted a
literature review of published host-trait microbiome prediction
studies that used cross-validation and reported a measure of
prediction accuracy. A full table appears in the Supplement,
including links to each of the 18 studies with 54 reported datasets
represented. As diﬀerent studies used vastly diﬀerent protocols
for OTU generation and preprocessing, for this main paper
we focused on the 17 reported datasets that compared at least
two competing measures of prediction accuracy. As diﬀerent studies used vastly diﬀerent protocols for OTU generation and
preprocessing, for this main paper we focused on the 17 reported
datasets that compared at least two competing measures of
prediction accuracy. All of the datasets were using human hosts,
except for Rousk et al. (2010) (where pH in soil samples was
the “trait”) and Moitinho-Silva et al. (2017), where microbial
abundance in sponges was the trait.

Frontiers in Genetics | www.frontiersin.org 9 June 2019 | Volume 10 | Article 579 Zhou and Gallins Host Trait Prediction and initial numbers of OTUs: (1) The Singh et al. (2015) data
set, containing 201 EDD (enteric diarrheal disease) cases vs.
82 healthy controls with 1, 325 OTUs. (2) The Vincent et al.
(2013) data set, with 25 CDI (Clostridium diﬃcile infection)
cases vs. 25 healthy controls and 763 OTUs. (3a) The Goodrich
et al. (2014) dataset, which categorized the hosts into 135 obese
cases vs. 279 controls, based on body mass index (BMI), with
a total of 11, 225 OTUs. In this dataset, individuals came from
the TwinsUK population, so we included only one individual
from each twin-pair. (3b) The same Goodrich et al. (2014)
dataset, but using BMI directly as a continuous phenotype for the
same 414 individuals. The microbiome samples for each dataset
were obtained from stool, and we analyzed one sample per
individual throughout.

We performed 100 rounds of 5-fold cross-validation for each
supervised method, using diﬀerent random splits for each round.
For binary traits, the estimated group probability ˆP(Y = 1|X)
was used to estimate the group assignment. These estimates were
further averaged over the cross-validation rounds. Performance
was evaluated using the AUC. For continuous traits, the direct
estimate ˆy was used, averaged over cross-validations, with
performance criterion R.

Frontiers in Genetics | www.frontiersin.org 10 June 2019 | Volume 10 | Article 579 Zhou and Gallins Host Trait Prediction R code for the comparisons is available at https://sites.
google.com/ncsu.edu/zhouslab/home/software?, and here we list
the packages and settings used. Five-fold cross-validation was
used throughout, and we additionally checked for plausibility.
For example,
the out-of-bag accuracy estimates from the
random forest procedure were compared to our cross-validated
estimates and shown to match closely. All machine learning
methods were used for each dataset as applicable (for example,
LDA was applicable only for the discrete trait datasets).
All predictions used probability estimates for the discrete
traits. The random forest method used randomForest
with ntree=500, mtry=sqrt(ncol(X)). The gradient
boosting (Gboost) decision-tree approach used xgboost, with
nrounds=10 and objective= “binary:logistic”
for the discrete trait. For the decision tree method, aspects,
such as tree depth used default values. The Lasso, Ridge,
and Elastic Net approaches used the package and method
glmnet, with lambda=seq(0,1,by=0.1). The k-NN
approach used caret with k = 5 and default (equal) neighbor
weighting. The neural net used neuralnet with hidden=1,
linear.output=F. Linear discriminant analysis used the
lda package with tol=0.

5. RESULTS were presented as AUC, accuracy, or balanced accuracy, but in
all instances higher values reﬂect better performance. Although
not all methods were represented in each study, some general
conclusions can be made. When random forests were applied,
they were either the most accurate or competitive [with the
exception of Nakano (2018)] (Nakano et al., 2018). Various
forms of neural networks often performed well, although there
is some question whether the tuning complexity is warranted. An
exception is Rousk (2010) as analyzed by Ditzler et al. (2015b), in
which some neural networks (perceptions) performed especially
well, but the sample size was small n = 22. In the datasets
analyzed by Ditzler et al. (2015b), the complexity and number of
nodes in neural networks showed little consistent relationship to
performance. Most of the studies used some form of higher-level
OTU aggregation, sometimes as high as the phylum level.

Table 1 shows the comparative results of 17 datasets analyzed
with numerous prediction methods. The results for discrete traits Summarizing the results after using BMI as a continuous trait
in the Goodrich dataset, the bar graph (Figure 2D) shows the FIGURE 5 | Scatterplot comparing the average AUCs between the full dataset and the HFE subset. (A) Singh dataset, (B) Vincent dataset, (C) Goodrich dataset.

As an overall summary, collapsing to the genus level brought
some improvement to the poorer perform prediction methods in
the Singh et al. (2015) dataset, and few other broad patterns were
apparent. In contrast, the use of cross-validated HFE produced
a great improvement in AUC in most instances (Figure 4). For
the Goodrich et al. (2014) and Singh et al. (2015) datasets, most
methods were improved and brought to similar AUC values.
For the Vincent dataset, again most prediction methods were
improved by HFE feature-reduction, but the results were less
uniform. Another pattern that is apparent in the scatterplots,
perhaps expected,
is that HFE brought diminishing returns
for methods that already perform well. The one prediction
method that was not improved demonstrably by HFE was k-
NN (with k = 5).

The Supplementary Material
online
2019.00579/full#supplementary-material Supplementary Table 1 | Full table of published prediction accuracies.
