71_PARAGRAPHS

levels of taxonomy, with intriguing thoughts about the
of
interplay and use of molecular function descriptors vs. taxonomic
descriptors, the reader is referred to Knights et al. and
Xu et al.  However, many of the principles discussed here
apply regardless of the feature type..

2.1. Notation and Sampling Considerations
Let X be an m × n matrix of microbiome count data, where
m is the number of OTU features and n is the number of
samples. Let y be a vector of length n with the microbiome
host trait. Commonly a trait will be a binary outcome (e.g.,
case/control status, coded 1/0), or a continuous trait, such as
body mass index (BMI). Here our use of microbiome features
as predictive of a trait does not imply or assume causality. We
note that case/control study designs often involve oversampling
of one type (often cases) relative to the general population. A
prediction rule might explicitly use this information, for example
by a simple application of Bayes’ rule (Tibshirani et al., 2003),
with prior probabilities reﬂecting those in the general population.
Such sampling considerations are beyond our scope, and we
refer the reader to Chawla  Here we consider our sample
dataset to be representative of the population of its intended
downstream use..

2.2. Transformation and Normalization
Normalization is an essential process to ensure comparability of
data across samples (Weiss et al., 2017), largely to account for
the large variability in library sizes (total number of sequencing
reads across diﬀerent samples). The basic issues are similar
to those encountered in expression sequence normalization
(de Kok et al., 2005), but
less is currently known about
sources of potential bias to inform microbiome normalization.
Normalization methods assessed by Weiss et al. included
cumulative sum scaling, variance stabilization, and trimmed-
mean by M-values. Randolph et al. utilized the centered
log-ratio (CLR) transform of the relative abundance vectors,
based on a method developed by Aitchison  replacing
zeros with a small positive value. As part of their motivation,
Randolph et al. pointed out that standard cumulative
sum scaling places the normalized data vectors in a simplex,
with potential consequences for kernel-based discovery methods
(Randolph et al., 2018)..

3.3.1. Regression
The use of linear models enables simple ﬁtting of continuous
traits y as a function of feature vectors. However, if m ≥ n then
structural overﬁtting occurs, and even if m < n accuracy is often
improved by using penalized (regularized) models. For the model
y = Xβ + ǫ, the training loss is Pi(yi − ˆyi)2 the most commonly-
used regularization methods are ridge regression (Hoerl and
Kennard, 1970) and Lasso (Tibshirani, 1996) regression, which
respectively use penalties λ Pi β2
i and λ Pi |βi| (not including
the intercept) to the training loss. For binary class prediction,
the approach is essentially the same, applying a generalized linear.

3.3.2. Linear Discriminant Analysis (LDA)
For binary traits, this approach ﬁnds a linear combination of
OTUs in the training data that models the multivariate mean
diﬀerences between classes (Lachenbruch and Goldstein, 1979).
Classical LDA assumes that feature data arise from two diﬀerent
multivariate normal densities according to y = 0 and y = 1,
i.e., MVN(µ0, 6) and MVN(µ1, 6) (Figure 1A). The prediction
value is the estimate of the posterior mean E(Y|x) = Pr(Y =
1|X), used because it minimizes mean-squared error..

3.3.4. Similarity Matrices and Related Kernel Methods
Some applications of microbiome association testing have
compared similarity matrices across features to similarity of
traits (Zhao and Shojaie, 2016). A closely-related approach is to
ﬁrst compute principal component (PC) scores, which may be
obtained from OTU sample-sample correlation matrices (Zhou
et al., 2018), and to use these PC scores as trait predictors.
Kernel-penalized regression, an extension of PCA, was utilized by
Randolph et al.  in their microbiome data analysis. They
applied a signiﬁcance test for their graph-constrained estimation
method, called Grace (Zhao and Shojaie, 2016), to test for
association between microbiome species and their trait. However,
trait prediction is not available in their software..

FIGURE 1 | Schematic illustration of several machine learning prediction methods using case/control (red/blue) status. For two features, (A) illustrates linear
discrimination methods. The solid line shows the linear discriminant line corresponding to equally probable outcomes, while the dashed line shows the midpoint of the
maximum-margin support vector machine. (B) For k-nearest neighbors, the gray point is predicted using an average of the neighbors (red, in this instance). (C)
Decision tree ensembles include random forests, which average over bootstrapped trees, and boosted trees, where successive residuals are used for ﬁtting. Trees may
not extend to the level of individual observations, and modal or mean values in the terminal nodes are used for prediction. (D) A neural network with few hidden layers..

TABLE 1 | Review of published prediction accuracy comparisons..


Recursive neural network
(RNN) .

Recursive neural network
(RNN) .


Recursive neural network
(RNN) .

Recursive neural network
(RNN) .


Recursive neural network
(RNN) .

Recursive neural network
(RNN) .

The prediction Pearson correlation (R) between cross-
is a commonly-
validated predicted and actual y values
used standard of accuracy for continuous traits, although
many procedures are designed to minimize the mean-squared
prediction error Pi(yi − ˆyi)2. R ≤ 0 corresponds to no predictive
value, and R = 1 to perfect prediction. We advocate R as a
criterion because it is simple and applicable to many prediction
procedures. Some prediction procedures may have an oﬀset or
proportional bias in prediction that may harm the mean-squared
error, even if R is favorable. A post-hoc linear rescaling of the.

4.1. A Literature Review
We conducted a literature review of published host-trait
microbiome prediction studies that used cross-validation and
reported a measure of prediction accuracy. We conducted a
literature review of published host-trait microbiome prediction
studies that used cross-validation and reported a measure of
prediction accuracy. A full table appears in the Supplement,
including links to each of the 18 studies with 54 reported datasets
represented. As diﬀerent studies used vastly diﬀerent protocols
for OTU generation and preprocessing, for this main paper
we focused on the 17 reported datasets that compared at least
two competing measures of prediction accuracy. As diﬀerent.

studies used vastly diﬀerent protocols for OTU generation and
preprocessing, for this main paper we focused on the 17 reported
datasets that compared at least two competing measures of
prediction accuracy. All of the datasets were using human hosts,
except for Rousk et al. (where pH in soil samples was
the “trait”) and Moitinho-Silva et al.  where microbial
abundance in sponges was the trait..

4.2. Analyses of Data Using Competing
Methods
learning
In
the
methods ourselves using datasets
from MicrobiomeHD
(https://github.com/cduvallet/microbiomeHD), a standardized
database of human gut microbiome studies in health and
disease. This database includes publicly available 16S rRNA
data from published case-control and other studies and their
associated patient metadata. The MicrobiomeHD database
these datasets are
and original publications
described in Duvallet et al.  Raw sequencing data
for each study was downloaded and processed through a
standardized pipeline..

cases vs. 25 healthy controls and 763 OTUs. The Goodrich
et al. dataset, which categorized the hosts into 135 obese
cases vs. 279 controls, based on body mass index (BMI), with
a total of 11, 225 OTUs. In this dataset, individuals came from
the TwinsUK population, so we included only one individual
from each twin-pair. 
dataset, but using BMI directly as a continuous phenotype for the
same 414 individuals. The microbiome samples for each dataset
were obtained from stool, and we analyzed one sample per
individual throughout..

Following the ﬁltering recommendations applied by Duvallet
et al.  we removed samples with fewer than 100 reads
and OTUs with fewer than 10 reads. We also removed OTUs
which were present in <1% of samples from the Vincent et al.
datasets, and
<5% of samples from the Goodrich et al. datasets, since.

We performed 100 rounds of 5-fold cross-validation for each
supervised method, using diﬀerent random splits for each round.
For binary traits, the estimated group probability ˆP(Y = 1|X)
was used to estimate the group assignment. These estimates were
further averaged over the cross-validation rounds. Performance
was evaluated using the AUC. For continuous traits, the direct
estimate ˆy was used, averaged over cross-validations, with
performance criterion R..

R code for the comparisons is available at https://sites.
google.com/ncsu.edu/zhouslab/home/software?, and here we list
the packages and settings used. Five-fold cross-validation was
used throughout, and we additionally checked for plausibility.
For example,
the out-of-bag accuracy estimates from the
random forest procedure were compared to our cross-validated
estimates and shown to match closely. All machine learning
methods were used for each dataset as applicable (for example,
LDA was applicable only for the discrete trait datasets).
All predictions used probability estimates for the discrete
traits. The random forest method used randomForest
with ntree=500, mtry=sqrt(ncol(X)). The gradient
boosting (Gboost) decision-tree approach used xgboost, with
nrounds=10 and objective= “binary:logistic”
for the discrete trait. For the decision tree method, aspects,
such as tree depth used default values. The Lasso, Ridge,
and Elastic Net approaches used the package and method
glmnet, with lambda=seq The k-NN
approach used caret with k = 5 and default (equal) neighbor
weighting. The neural net used neuralnet with hidden=1,
linear.output=F. Linear discriminant analysis used the
lda package with tol=0..

were presented as AUC, accuracy, or balanced accuracy, but in
all instances higher values reﬂect better performance. Although
not all methods were represented in each study, some general
conclusions can be made. When random forests were applied,
they were either the most accurate or competitive [with the
exception of Nakano  Various
forms of neural networks often performed well, although there
is some question whether the tuning complexity is warranted. An
exception is Rousk  in
which some neural networks (perceptions) performed especially
well, but the sample size was small n = 22. In the datasets
analyzed by Ditzler et al.  the complexity and number of
nodes in neural networks showed little consistent relationship to
performance. Most of the studies used some form of higher-level
OTU aggregation, sometimes as high as the phylum level..

Table 1 shows the comparative results of 17 datasets analyzed
with numerous prediction methods. The results for discrete traits.

As an overall summary, collapsing to the genus level brought
some improvement to the poorer perform prediction methods in
the Singh et al. dataset, and few other broad patterns were
apparent. In contrast, the use of cross-validated HFE produced
a great improvement in AUC in most instances (Figure 4). For
the Goodrich et al. datasets, most
methods were improved and brought to similar AUC values.
For the Vincent dataset, again most prediction methods were
improved by HFE feature-reduction, but the results were less
uniform. Another pattern that is apparent in the scatterplots,
perhaps expected,
is that HFE brought diminishing returns
for methods that already perform well. The one prediction
method that was not improved demonstrably by HFE was k-
NN (with k = 5)..

For more advanced topics, we point the reader to analysis of
microbiome time series data, using techniques, such as MDSINE
(Bucci et al., 2016), which uses dynamical systems inference to
estimate and forecast trajectories of microbiome subpopulations.
Other uses of dynamical systems have concentrated mainly on
observable phenotypes/experiemental conditions, rather than
using microbiome status for prediction (Brooks et al., 2017). In
addition, the use of co-measured features, such as metabolites
(Franzosa et al., 2019), oﬀers potentially useful
information
for integrative analyses. As another example of the use of
ancillary information, an intriguing approach has also been used
to predict biotransformation of speciﬁc drugs and xenobiotics
by gut bacterial enzymes (Sharma et al., 2017). We also
note that our review/tutorial has for clarity placed feature
engineering, which may be viewed as a form of statistical
regularization, as a separately-handled issue from the penalized
prediction modeling. Some modern sparse regression and
kernel modeling methods seek additional predictive ability by
combining feature regularization and prediction in a single step,
e.g., Xiao et al. .

Supplementary Table 1 | Full table of published prediction accuracies..

Ai, L., Tian, H., Chen, Z., Chen, H., Xu, J., and Fang, J. Y.  Systematic
evaluation of supervised classiﬁers for fecal microbiota-based prediction of
colorectal cancer. Oncotarget 8, 9546–9556. doi: 10.18632/oncotarget.14488
Aitchison, J.  The statistical analysis of compositional data. J. R. Stat. Soc..

Breiman, L.  Random forests machine learning. Mach. Learn. 45, 5–32..

Ananthakrishnan, A. N., Luo, C., Yajnik, V., Khalili, H., Garber, J. J., Stevens,
B. W., et al.  Gut microbiome function predicts response to anti-
integrin biologic therapy in inﬂammatory bowel diseases. Cell Host Microbe 21,
603–610. doi: 10.1016/j.chom.2017.04.010.

Brooks, J. P., Buck, G. A., Chen, G., Diao, L., Edwards, D. J., Fettweis,
J. M., et al.  Changes in vaginal community state types reﬂect
major shifts in the microbiome. Microb. Ecol. Health Dis. 28:1303265.
doi: 10.1080/16512235.2017.1303265.

Cani, P. D.  Human gut microbiome: hopes, threats and promises. Gut 67,.

Caporaso, J. G., Lauber, C. L., Costello, E. K., Berg-Lyons, D., Gonzalez, A.,
Stombaugh, J., et al.  Moving pictures of the human microbiome.
Genome Biol. 12:R50. doi: 10.1186/gb-2011-12-5-r50.

Chawla, N. V.  “Data mining for imbalanced datasets: an overview,” in Data
Mining and Knowledge Discovery Handbook, eds O. Maimon and L. Rokach
(Boston, MA: Springer), 875–886..

Cortes, C. and Vapnik, V.  Support-vector networks. Mach. Learn. 20,.

Crookston, N. L. and Finley, A. O.  Yaimpute: an r package for knn.

de Kok, J. B., Roelofs, R. W., Giesendorf, B. A., Pennings, J. L., Waas, E. T., Feuth,
T., et al.  Normalization of gene expression measurements in tumor
tissues: comparison of 13 endogenous control genes. Lab. Invest. 85, 154–159.
doi: 10.1038/labinvest.3700208.

 Fizzy:
feature subset selection for metagenomics. BMC Bioinformatics 16:358.
doi: 10.1186/s12859-015-0793-8.

Ditzler, G., Polikar, R., and Rosen, G.  Multi-layer and recursive neural
networks for metagenomic classiﬁcation. IEEE Trans. Nanobiosci. 14, 608–616.
doi: 10.1109/TNB.2015.2461219.

Friedman, J. H.  Greedy function approximation: a gradient boosting.

Friedman, J. H.  Stochastic gradient boosting. Comput. Stat. Data Anal. 38,.

Gevers, D., Kugathasan, S., Denson, L. A., Vázquez-Baeza, Y., Van Treuren, W.,
Ren, B., et al.  The treatment-naive microbiome in new-onset Crohn’s
disease. Cell Host Microbe. 15, 382–392. doi: 10.1016/j.chom.2014.02.005.

Gilbert, J. A., Blaser, M. J., Caporaso, J. G., Jansson, J. K., Lynch, S. V., and Knight,
R.  Current understanding of the human microbiome. Nat. Med. 24:392.
doi: 10.1038/nm.4517.

Goodrich, J. K., Waters, J. L., Poole, A. C., Sutter, J. L., Koren, O., Blekhman, R.,
et al.  Human genetics shape the gut microbiome. Cell 159, 789–799.
doi: 10.1016/j.cell.2014.09.053.

Ho, T. K.  “Random decision forests,” in Document Analysis and
the Third International Conference on.

Hoerl, A. E. and Kennard, R. W.  Ridge regression: applications to.

Hu, T., Gallins, P., and Zhou, Y.-H.  A zero-inﬂated beta-binomial model.

Johnson, H. R., Trinidad, D. D., Guzman, S., Khan, Z., Parziale, J. V., DeBruyn,
J. M., et al.  A machine learning approach for using the postmortem
skin microbiome to estimate the postmortem interval. PLoS ONE 11:e0167370.
doi: 10.1371/journal.pone.0167370.

Karlsson, F. H., Tremaroli, V., Nookaew, I., Bergström, G., Behre, C. J., Fagerberg,
B., et al.  Gut metagenome in European women with normal, impaired
and diabetic glucose control. Nature 498, 99–103. doi: 10.1038/nature12198
Kinross, J. M., Darzi, A. W., and Nicholson, J. K.  Gut microbiome-host
interactions in health and disease. Genome Med. 3:14. doi: 10.1186/gm228
Knight, R., Vrbanac, A., Taylor, B. C., Aksenov, A., Callewaert, C., Debelius, J.,
et al.  Best practices for analysing microbiomes. Nat. Rev. Microbiol. 16,
410–422. doi: 10.1038/s41579-018-0029-9.

Lachenbruch, P. A. and Goldstein, M.  Discriminant analysis. Biometrics 35,.

Mallick, H., Ma, S., Franzosa, E. A., Vatanen, T., Morgan, X. C., and Huttenhower,
C.
 Experimental design and quantitative analysis of microbial
community multiomics. Genome Biol. 18:228. doi: 10.1186/s13059-017-1359-z
Mande, S. S., Mohammed, M. H., and Ghosh, T. S.  Classiﬁcation of
metagenomic sequences: methods and challenges. Brief. Bioinformatics 13,
669–681. doi: 10.1093/bib/bbs054.

McDonald, D., Price, M. N., Goodrich, J., Nawrocki, E. P., DeSantis, T. Z., Probst,
A., et al.  An improved greengenes taxonomy with explicit ranks for
ecological and evolutionary analyses of bacteria and archaea. ISME J. 6:610.
doi: 10.1038/ismej.2011.139.

Nakano, Y., Suzuki, N., and Kuwata, F.  Predicting oral malodour based
on the microbiota in saliva samples using a deep learning approach. BMC Oral
Health 18:128. doi: 10.1186/s12903-018-0591-6.

Qin, J., Li, Y., Cai, Z., Li, S., Zhu, J., Zhang, F., et al.  A metagenome-
wide association study of gut microbiota in type 2 diabetes. Nature 490, 55–60.
doi: 10.1038/nature11450.

Qin, N., Yang, F., Li, A., Prifti, E., Chen, Y., Shao, L., et al.  Alterations
the human gut microbiome in liver cirrhosis. Nature 513, 59–64..

Randolph, T. W., Zhao, S., Copeland, W., Hullar, M., Shojaie, A.  Kernel-
penalized regression for analysis of microbiome data. Ann. Appl. Stat. 12,
540–566. doi: 10.1214/17-AOAS1102.

Reiman, D., Metwally, A., and Dai, Y.  Using convolutional neural networks
to explore the microbiome. Conf. Proc. IEEE Eng. Med. Biol. Soc. 2017,
4269–4272. doi: 10.1109/EMBC.2017.8037799.

Robinson, C. M. and Pfeiﬀer, J. K.  Viruses and the microbiota. Annu. Rev..

Ross, M. C., Muzny, D. M., McCormick, J. B., Gibbs, R. A., Fisher-Hoch, S. P.,
and Petrosino, J. F.  16s Gut community of the cameron county hispanic
cohort. Microbiome 3:7. doi: 10.1186/s40168-015-0072-y.

Rothschild, D., Weissbrod, O., Barkan, E., Kurilshikov, A., Korem, T., Zeevi, D.,
et al.  Environment dominates over host genetics in shaping human gut
microbiota. Nature 555:210. doi: 10.1038/nature25973.

Rousk, J., Bååth, E., Brookes, P. C., Lauber, C. L., Lozupone, C., Caporaso, J. G.,
et al.  Soil bacterial and fungal communities across a ph gradient in an
arable soil. ISME J. 4:1340. doi: 10.1038/ismej.2010.58.

Sharma, A. K., Jaiswal, S. K., Chaudhary, N., and Sharma, V. K.  A
novel approach for the prediction of species-speciﬁc biotransformation of
xenobiotic/drug molecules by the human gut microbiota. Sci. Rep. 7:9751.
doi: 10.1038/s41598-017-10203-6.

Xiao, J., Chen, L., Yu, Y., Zhang, X., and Chen, J.  A phylogeny-
regularized sparse regression model for predictive modeling of microbial
10.3389/fmicb.2018.
community data. Front. Microbiol.
03112.

Xu, Z., Malmer, D., Langille, M. G., Way, S. F., and Knight, R.  Which is
more important for classifying microbial communities: who’s there or what they
can do? ISME J. 8:2357. doi: 10.1038/ismej.2014.157.

Zhao, S. and Shojaie, A.  A signiﬁcance test for graph-constrained.

Zhou, Y.-H., Marron, J. S., and Wright, F. A.  Computation of ancestry
scores with mixed families and unrelated individuals. Biometrics 74, 155–164.
doi: 10.1111/biom.12708.

Zou, H., and Hastie, T.  Regularization and variable selection via the elastic.

Tibshirani, R.  Regression shrinkage and selection via the lasso. J. R. Stat..

Tibshirani, R., Hastie, T., Narasimhan, B., and Chu, G.  Class prediction by
nearest shrunken centroids, with applications to dna microarrays. Stat. Sci. 18,
104–117. doi: 10.1214/ss/1056397488.

Turnbaugh, P. J., Ley, R. E., Hamady, M., Fraser-Liggett, C. M., Knight, R.,
and Gordon, J. I.  The human microbiome project. Nature 449:804.
doi: 10.1038/nature06244.

J., Behr, M. A.,
Dewar, K., et al.  Reductions in intestinal clostridiales precede the
development of nosocomial clostridium diﬃcile infection. Microbiome 1:18.
doi: 10.1186/2049-2618-1-18